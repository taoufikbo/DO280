Objectif de la formation 




Dans OpenShift, il existe plusieurs types de **nÅ“uds**, chacun ayant des rÃ´les et des configurations DNS spÃ©cifiques. Voici un rÃ©sumÃ© des principaux types de nÅ“uds et leurs configurations DNS associÃ©es.

---

### **1. Types de nÅ“uds dans OpenShift**
#### **1.1. NÅ“uds de contrÃ´le (Control Plane / Master Nodes)**
- RÃ´les :  
  - GÃ¨rent lâ€™Ã©tat du cluster.
  - HÃ©bergent les composants critiques comme etcd, le scheduler, le contrÃ´leur API.
- CaractÃ©ristiques :
  - Ne sâ€™occupent gÃ©nÃ©ralement pas de lâ€™exÃ©cution des workloads (sauf dans des environnements compacts).
- Configurations DNS associÃ©es :
  - Chaque nÅ“ud master doit pouvoir rÃ©soudre lâ€™adresse du cluster API (`api.<cluster_name>.<domain>`) et celle des autres masters.
  - Exemple dâ€™entrÃ©es DNS :
    ```
    api.cluster.example.com â†’ 192.168.1.10
    api-int.cluster.example.com â†’ 192.168.1.11
    master-1.cluster.example.com â†’ 192.168.1.12
    master-2.cluster.example.com â†’ 192.168.1.13
    master-3.cluster.example.com â†’ 192.168.1.14
    ```

---

#### **1.2. NÅ“uds de calcul (Worker Nodes)**
- RÃ´les :
  - HÃ©bergent les applications et les workloads.
  - Peuvent Ãªtre organisÃ©s en pools selon des contraintes (GPU, stockage, rÃ©seau spÃ©cifique...).
- Configurations DNS associÃ©es :
  - Ils doivent pouvoir rÃ©soudre lâ€™API du cluster (`api.cluster.example.com`) et les autres services internes.
  - Les nÅ“uds workers doivent aussi pouvoir rÃ©soudre le service de registre interne (`default-route-openshift-image-registry.apps.cluster.example.com`).
  - Exemple dâ€™entrÃ©es DNS :
    ```
    worker-1.cluster.example.com â†’ 192.168.1.21
    worker-2.cluster.example.com â†’ 192.168.1.22
    ```

---

#### **1.3. NÅ“uds dâ€™infrastructure (Infrastructure Nodes)**
- RÃ´les :
  - HÃ©bergent les services essentiels au cluster (registre dâ€™images, router, monitoring, loggingâ€¦).
- Configurations DNS associÃ©es :
  - Doivent Ãªtre accessibles par les autres nÅ“uds pour exposer les services internes.
  - Ils ont souvent des noms spÃ©cifiques pour les distinguer des workers classiques :
    ```
    infra-1.cluster.example.com â†’ 192.168.1.31
    infra-2.cluster.example.com â†’ 192.168.1.32
    ```

---

### **2. Configuration DNS requise dans OpenShift**
#### **2.1. DNS Externe (Obligatoire pour lâ€™installation)**
- **EntrÃ©es A et CNAME** pour les points dâ€™accÃ¨s API :
  ```
  api.cluster.example.com â†’ IP du load balancer (ou master)
  api-int.cluster.example.com â†’ IP du load balancer interne
  ```

#### **2.2. DNS Interne (gÃ©rÃ© par CoreDNS ou dnsmasq)**
- OpenShift utilise un **service DNS interne** basÃ© sur CoreDNS pour la rÃ©solution des services internes.
- Exemple de noms de service internes :
  ```
  etcd-0.cluster.example.com â†’ 192.168.1.12
  etcd-1.cluster.example.com â†’ 192.168.1.13
  etcd-2.cluster.example.com â†’ 192.168.1.14
  ```

- Les pods et services utilisent une rÃ©solution DNS basÃ©e sur `.cluster.local`, par exemple :
  ```
  my-app.my-namespace.svc.cluster.local
  ```
### ğŸ”¹ **Notion de "Tenant" dans OpenShift**  

Dans OpenShift, un **tenant** reprÃ©sente un **groupe isolÃ© dâ€™utilisateurs et de workloads** qui partagent des ressources tout en restant cloisonnÃ©s des autres groupes. OpenShift nâ€™a pas un concept de "tenant" au sens strict, mais il permet de mettre en place une **multi-tenancy** grÃ¢ce Ã  plusieurs mÃ©canismes.

---

### ğŸ”¹ **Les MÃ©canismes de Multi-Tenancy dans OpenShift**  

| **MÃ©canisme**       | **RÃ´le** |
|---------------------|---------|
| **Namespaces (Projects)** | Isolation des ressources et des workloads pour chaque tenant. |
| **RBAC (Role-Based Access Control)** | Gestion des droits et permissions des utilisateurs par projet. |
| **Network Policies** | Isolation rÃ©seau entre tenants/pods. |
| **Resource Quotas & LimitRanges** | Limitation des ressources (CPU, mÃ©moire, etc.) par tenant. |
| **Security Contexts & SCC (Security Context Constraints)** | ContrÃ´le de la sÃ©curitÃ© des conteneurs et des permissions. |

---

### ğŸ”¹ **1ï¸âƒ£ Isolation des Tenants avec des Namespaces**  

Un namespace (`project` dans OpenShift) est un espace de travail dÃ©diÃ© aux workloads dâ€™un tenant. Chaque tenant peut avoir son propre namespace oÃ¹ il exÃ©cute ses applications.

ğŸ“Œ **Exemple : CrÃ©er un namespace pour un tenant nommÃ© "team1"**
```bash
oc new-project team1 --description="Tenant Team1" --display-name="Team 1"
```
â¡ Ce namespace isole les ressources et Ã©vite toute interfÃ©rence avec dâ€™autres tenants.

---

### ğŸ”¹ **2ï¸âƒ£ Gestion des Droits avec RBAC**  

OpenShift utilise **RBAC (Role-Based Access Control)** pour dÃ©finir quels utilisateurs ou groupes peuvent accÃ©der Ã  quels namespaces.

ğŸ“Œ **Exemple : Donner accÃ¨s Ã  "team1" Ã  un utilisateur spÃ©cifique**
```bash
oc adm policy add-role-to-user admin user1 -n team1
```
â¡ Lâ€™utilisateur `user1` a un rÃ´le dâ€™**admin** sur le namespace `team1`, mais pas sur les autres namespaces.

---

### ğŸ”¹ **3ï¸âƒ£ Isolation RÃ©seau avec NetworkPolicies**  

Par dÃ©faut, dans OpenShift SDN, tous les pods peuvent communiquer entre eux. Pour isoler les tenants, on utilise **les NetworkPolicies**.

ğŸ“Œ **Exemple : EmpÃªcher tout trafic entrant dans les pods du tenant "team1" sauf depuis son namespace**  
```yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-external
  namespace: team1
spec:
  podSelector: {}
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: team1
```
â¡ Cette rÃ¨gle **bloque tout trafic provenant dâ€™autres namespaces**, sauf `team1` lui-mÃªme.

---

### ğŸ”¹ **4ï¸âƒ£ Gestion des Ressources avec Resource Quotas**  

On peut limiter les ressources disponibles pour chaque tenant pour Ã©viter quâ€™un utilisateur monopolise le cluster.

ğŸ“Œ **Exemple : Limiter un namespace Ã  4 CPU et 8 Go de RAM**
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-team1
  namespace: team1
spec:
  hard:
    requests.cpu: "4"
    requests.memory: "8Gi"
    limits.cpu: "8"
    limits.memory: "16Gi"
```
â¡ **Garantit que le tenant "team1" ne dÃ©passe pas ces ressources.**

---

### ğŸ”¹ **5ï¸âƒ£ SÃ©curitÃ© des Conteneurs avec SCC**  

OpenShift utilise **Security Context Constraints (SCC)** pour limiter les actions possibles des conteneurs dans un namespace.

ğŸ“Œ **Exemple : EmpÃªcher un tenant dâ€™exÃ©cuter des conteneurs en root**
```bash
oc adm policy add-scc-to-group restricted system:serviceaccounts:team1
```
â¡ **Applique une politique de sÃ©curitÃ© stricte sur les conteneurs du tenant "team1".**

---

### ğŸ”¹ **ğŸ“Œ Conclusion : Comment bien gÃ©rer la multi-tenancy ?**  

âœ” **CrÃ©er un namespace par tenant**  
âœ” **Configurer des rÃ´les avec RBAC** pour Ã©viter que les tenants ne voient dâ€™autres ressources  
âœ” **Appliquer des NetworkPolicies** pour isoler les communications  
âœ” **Limiter les ressources avec Resource Quotas**  
âœ” **Restreindre les permissions des conteneurs avec SCC**  

Tu veux mettre en place une sÃ©paration des tenants dans un environnement spÃ©cifique ? ğŸ˜Š
---

### ğŸ”¹ **Architecture dâ€™un opÃ©rateur OpenShift/Kubernetes avec CRD**  

Un **opÃ©rateur** dans OpenShift/Kubernetes est une application qui automatise la gestion dâ€™un logiciel complexe sur un cluster. Il repose sur le **pattern de contrÃ´le** et utilise des **Custom Resource Definitions (CRD)** pour gÃ©rer des objets spÃ©cifiques Ã  une application.

---

## **ğŸ”¹ 1ï¸âƒ£ Composants clÃ©s dâ€™un opÃ©rateur avec CRD**  

| **Composant**  | **RÃ´le** |
|---------------|---------|
| **Custom Resource Definition (CRD)** | DÃ©finit un nouvel objet personnalisÃ© dans lâ€™API Kubernetes. |
| **Custom Resource (CR)** | Instance du CRD qui dÃ©crit la configuration dâ€™un service. |
| **Operator Controller** | Boucle de contrÃ´le qui surveille les CR et applique les changements nÃ©cessaires. |
| **Reconciler** | Logique mÃ©tier qui sâ€™assure que lâ€™Ã©tat actuel correspond Ã  lâ€™Ã©tat dÃ©sirÃ©. |
| **RBAC (Role-Based Access Control)** | Permissions dâ€™accÃ¨s pour lâ€™opÃ©rateur dans le cluster. |

---

## **ğŸ”¹ 2ï¸âƒ£ Architecture globale**  

Lâ€™opÃ©rateur suit le pattern **Controller-Operator** et fonctionne selon les Ã©tapes suivantes :  

1ï¸âƒ£ **DÃ©finition dâ€™un CRD** â†’ Ajoute un nouvel objet (`MyApp`) dans lâ€™API Kubernetes.  
2ï¸âƒ£ **CrÃ©ation dâ€™un CR** â†’ Un utilisateur crÃ©e une ressource personnalisÃ©e (`MyApp-instance`).  
3ï¸âƒ£ **Surveillance par le contrÃ´leur** â†’ Lâ€™opÃ©rateur dÃ©tecte les changements sur le CR.  
4ï¸âƒ£ **Reconciliation Loop** â†’ Lâ€™opÃ©rateur applique les changements en crÃ©ant/modifiant des ressources sous-jacentes (Pods, Services, ConfigMaps, etc.).  
5ï¸âƒ£ **Mise Ã  jour et gestion continue** â†’ Lâ€™opÃ©rateur surveille en permanence et corrige tout Ã©cart.

---

## **ğŸ”¹ 3ï¸âƒ£ Exemple dâ€™architecture technique**

```yaml
# ğŸ“Œ 1ï¸âƒ£ DÃ©finition du CRD (Custom Resource Definition)
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: myapps.example.com
spec:
  group: example.com
  names:
    kind: MyApp
    plural: myapps
  scope: Namespaced
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          replicas:
            type: integer
```

---

```yaml
# ğŸ“Œ 2ï¸âƒ£ CrÃ©ation dâ€™un CR (Custom Resource)
apiVersion: example.com/v1
kind: MyApp
metadata:
  name: myapp-instance
spec:
  replicas: 3
```

---

```go
// ğŸ“Œ 3ï¸âƒ£ ContrÃ´leur Go pour gÃ©rer le CR
func (r *MyAppReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    log := r.Log.WithValues("myapp", req.NamespacedName)

    // RÃ©cupÃ©rer l'Ã©tat actuel du CR
    var myApp examplev1.MyApp
    if err := r.Get(ctx, req.NamespacedName, &myApp); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }

    // VÃ©rifier et mettre Ã  jour les ressources (ex: Deployment)
    desiredReplicas := myApp.Spec.Replicas
    err := r.updateDeployment(ctx, myApp, desiredReplicas)
    if err != nil {
        log.Error(err, "Erreur lors de la mise Ã  jour")
        return ctrl.Result{}, err
    }

    return ctrl.Result{}, nil
}
```

---

## **ğŸ”¹ 4ï¸âƒ£ DÃ©ploiement et gestion de lâ€™opÃ©rateur**  

### âœ… **1. Construire lâ€™opÃ©rateur avec Operator SDK**  
```bash
operator-sdk init --domain=example.com --repo=github.com/example/my-operator
operator-sdk create api --group=example --version=v1 --kind=MyApp --resource --controller
```

### âœ… **2. DÃ©ployer lâ€™opÃ©rateur**  
```bash
make deploy
kubectl apply -f config/samples/example_v1_myapp.yaml
```

---

## **ğŸ“Œ Conclusion**
âœ” **Les CRD** permettent dâ€™ajouter des API personnalisÃ©es dans OpenShift/Kubernetes.  
âœ” **Lâ€™opÃ©rateur** surveille et applique lâ€™Ã©tat dÃ©sirÃ© en boucle.  
âœ” **Le reconciler** exÃ©cute la logique mÃ©tier pour crÃ©er/modifier les ressources Kubernetes.  

Tu veux un opÃ©rateur pour un besoin spÃ©cifique, comme OpenShift ou une solution cloud ? ğŸ˜Š

### ğŸ”¹ **Types dâ€™utilisateurs dans Kubernetes**  

Dans Kubernetes, les utilisateurs ne sont **pas** des objets gÃ©rÃ©s directement par lâ€™API (contrairement aux ressources comme les Pods ou les Services). Ils sont dÃ©finis de maniÃ¨re externe (via des certificats, des identitÃ©s IAM, etc.).  

Il existe **deux types principaux dâ€™utilisateurs** :  

| **Type**            | **Description** |
|---------------------|----------------|
| **Regular users (utilisateurs classiques)** | ReprÃ©sentent des humains accÃ©dant au cluster (ex: DevOps, Admins). |
| **System users (utilisateurs systÃ¨me)** | ReprÃ©sentent des services ou des composants internes de Kubernetes. |

---

## **ğŸ”¹ 1ï¸âƒ£ Regular Users (Utilisateurs classiques)**  

Les **utilisateurs rÃ©guliers** sont des **humains** qui interagissent avec le cluster via `kubectl`, `oc` (OpenShift), lâ€™API Kubernetes, ou des interfaces graphiques (comme OpenShift Console ou Lens).  

ğŸ“Œ **CaractÃ©ristiques :**  
âœ” Ne sont **pas stockÃ©s** dans Kubernetes (gÃ©rÃ©s par des systÃ¨mes externes).  
âœ” Authentification via **certificats X.509, OIDC, LDAP, IAM (Cloud)**, etc.  
âœ” AccÃ¨s contrÃ´lÃ© par **RBAC (Role-Based Access Control)**.  

ğŸ“Œ **Exemples de Regular Users :**  
- **Admin du cluster** (`admin`)  
- **DÃ©veloppeur** (`developer`)  
- **OpÃ©rateur DevOps** (`devops`)  

ğŸ“Œ **Exemple dâ€™authentification par certificat X.509**  
```bash
kubectl config set-credentials taoufik --client-certificate=taoufik.crt --client-key=taoufik.key
```
â¡ Ici, `taoufik` est un utilisateur classique identifiÃ© par un certificat.

---

## **ğŸ”¹ 2ï¸âƒ£ System Users (Utilisateurs systÃ¨me)**  

Les **utilisateurs systÃ¨me** sont des comptes utilisÃ©s par Kubernetes pour ses propres composants et services.  

ğŸ“Œ **CaractÃ©ristiques :**  
âœ” Ont un **prÃ©fixe `system:`** dans leur nom.  
âœ” GÃ©rÃ©s automatiquement par Kubernetes.  
âœ” UtilisÃ©s pour la communication interne entre les composants Kubernetes.  
âœ” AssignÃ©s Ã  des **ServiceAccounts** pour lâ€™authentification des Pods.  

ğŸ“Œ **Exemples de System Users :**  
| **Utilisateur**                | **RÃ´le** |
|---------------------------------|---------|
| `system:admin`                  | Administrateur du cluster (OpenShift). |
| `system:kube-controller-manager` | GÃ¨re les objets comme les Deployments, les Jobsâ€¦ |
| `system:kube-scheduler`         | Planifie lâ€™exÃ©cution des Pods sur les nÅ“uds. |
| `system:kubelet`                | ExÃ©cute les Pods sur un nÅ“ud spÃ©cifique. |
| `system:serviceaccount:<namespace>:<name>` | Compte attribuÃ© aux Pods. |

ğŸ“Œ **Exemple de ServiceAccount attribuÃ© Ã  un Pod :**  
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-app-sa
  namespace: my-namespace
```
â¡ Ce ServiceAccount `my-app-sa` peut Ãªtre utilisÃ© par un Pod pour interagir avec lâ€™API Kubernetes.

---

## **ğŸ”¹ 3ï¸âƒ£ DiffÃ©rences entre Regular Users et System Users**  

| **CritÃ¨re**        | **Regular Users** | **System Users** |
|--------------------|-----------------|----------------|
| **Type dâ€™utilisateur** | Humains | Services/Kubernetes |
| **StockÃ© dans Kubernetes ?** | âŒ Non (externe) | âœ… Oui (gÃ©rÃ© en interne) |
| **Authentification** | Certificat X.509, OIDC, IAM | ServiceAccount, RBAC |
| **Utilisation principale** | Interaction avec le cluster (`kubectl`, APIâ€¦) | Automatisation des composants Kubernetes |
| **Exemple dâ€™utilisateur** | `taoufik`, `devops` | `system:kube-scheduler`, `system:serviceaccount:default:my-app` |

---

## **ğŸ”¹ ğŸ“Œ Conclusion**  
âœ” **Regular Users** ğŸ‘‰ Pour les humains interagissant avec Kubernetes (admins, devs, ops).  
âœ” **System Users** ğŸ‘‰ Pour les composants internes de Kubernetes et les Pods.  
âœ” Lâ€™accÃ¨s est gÃ©rÃ© via **RBAC** et lâ€™authentification dÃ©pend du contexte (certificats, OIDC, ServiceAccounts).  

Tu veux configurer un accÃ¨s utilisateur spÃ©cifique sur un cluster OpenShift/K8s ? ğŸ˜Š

Voici un **diagramme de sÃ©quence** simplifiÃ© pour illustrer le processus de connexion Ã  l'API OpenShift avec deux types de comptes diffÃ©rents : un **compte local** et un **compte externe via Keycloak**.

---

### **ğŸ”¹ Diagramme de sÃ©quence : Connexion Ã  l'API OpenShift**

---

#### **1ï¸âƒ£ Connexion avec un compte local :**

1. **Utilisateur** envoie une demande de connexion Ã  l'API OpenShift.
2. **API OpenShift** redirige la demande vers l'authentification locale (par exemple via `htpasswd`, certificat, ou autres mÃ©canismes).
3. **Service dâ€™authentification OpenShift** vÃ©rifie les **identifiants locaux**.
4. Si **authentification rÃ©ussie**, **OpenShift** gÃ©nÃ¨re un **token dâ€™accÃ¨s** (Bearer Token).
5. Lâ€™**API OpenShift** rÃ©pond avec le **token dâ€™accÃ¨s**.
6. **Utilisateur** peut maintenant faire des requÃªtes API avec le **token dâ€™accÃ¨s** dans lâ€™en-tÃªte.

---

#### **2ï¸âƒ£ Connexion avec un compte externe via Keycloak :**

1. **Utilisateur** envoie une demande de connexion Ã  l'API OpenShift.
2. **API OpenShift** redirige la demande vers **Keycloak** (serveur d'identitÃ© externe).
3. **Keycloak** demande Ã  lâ€™utilisateur de sâ€™authentifier via **OIDC** (par exemple : via un formulaire de login).
4. **Utilisateur** saisit ses identifiants dans **Keycloak**.
5. **Keycloak** vÃ©rifie les identifiants de lâ€™utilisateur contre sa base de donnÃ©es ou un fournisseur d'identitÃ© (LDAP, etc.).
6. Si **authentification rÃ©ussie**, **Keycloak** gÃ©nÃ¨re un **token ID** (ID Token) et un **token dâ€™accÃ¨s** (Access Token).
7. **Keycloak** redirige lâ€™utilisateur vers l'**API OpenShift** avec ces tokens.
8. **API OpenShift** valide les tokens via le **provider OIDC** (Keycloak).
9. Si la validation rÃ©ussie, **OpenShift** gÃ©nÃ¨re un **token dâ€™accÃ¨s** valide pour lâ€™utilisateur et le renvoie.
10. **Utilisateur** utilise le **token dâ€™accÃ¨s** pour faire des requÃªtes Ã  lâ€™API OpenShift.

---

### **ğŸ”¹ Diagramme de sÃ©quence visuel :**

Voici une illustration pour mieux comprendre :

```plaintext
                    +-------------------+           +-------------------+           +-----------------+
                    |   Utilisateur     |           |   API OpenShift   |           |    Keycloak     |
                    +-------------------+           +-------------------+           +-----------------+
                             |                            |                               |
                             |     1. Demande de connexion                               |
                             | ------------------------> |                               |
                             |                            | 2. Authentification locale / OIDC|
                             |                            | <-------------------------+     |
                             |                            |                               |
                             |                            |                               |   
                             |                            | 3. Rediriger vers Keycloak (OIDC) |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            |                               |
                             |                            |                               |
                             |                            |    4. Demande dâ€™identifiants     |
                             |                            | <----------------------------     |
                             |                            |                               |
                             |                            | 5. VÃ©rification des identifiants |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            | 6. Token d'accÃ¨s + ID Token     |
                             |                            | <----------------------------     |
                             |                            |                               |
                             |                            | 7. Rediriger vers OpenShift     |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            | 8. Validation des tokens       |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            | 9. Retourner le token dâ€™accÃ¨s  |
                             |                            | <----------------------------     |
                             |                            |                               |
                             |                            | 10. RequÃªte API avec token dâ€™accÃ¨s|
                             | ------------------------> |                               |
```

---

### **ğŸ”¹ Conclusion**

- **Compte local** : Authentification interne avec OpenShift, pas besoin de service externe.
- **Compte Keycloak** : Utilisation de lâ€™OIDC pour l'authentification, avec un fournisseur externe (Keycloak), permettant une gestion centralisÃ©e des identitÃ©s.

Cela te semble-t-il clair ou tu veux explorer un cas dâ€™utilisation particulier ? ğŸ˜Š
