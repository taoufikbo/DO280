Objectif de la formation 




Dans OpenShift, il existe plusieurs types de **nœuds**, chacun ayant des rôles et des configurations DNS spécifiques. Voici un résumé des principaux types de nœuds et leurs configurations DNS associées.

---

### **1. Types de nœuds dans OpenShift**
#### **1.1. Nœuds de contrôle (Control Plane / Master Nodes)**
- Rôles :  
  - Gèrent l’état du cluster.
  - Hébergent les composants critiques comme etcd, le scheduler, le contrôleur API.
- Caractéristiques :
  - Ne s’occupent généralement pas de l’exécution des workloads (sauf dans des environnements compacts).
- Configurations DNS associées :
  - Chaque nœud master doit pouvoir résoudre l’adresse du cluster API (`api.<cluster_name>.<domain>`) et celle des autres masters.
  - Exemple d’entrées DNS :
    ```
    api.cluster.example.com → 192.168.1.10
    api-int.cluster.example.com → 192.168.1.11
    master-1.cluster.example.com → 192.168.1.12
    master-2.cluster.example.com → 192.168.1.13
    master-3.cluster.example.com → 192.168.1.14
    ```

---

#### **1.2. Nœuds de calcul (Worker Nodes)**
- Rôles :
  - Hébergent les applications et les workloads.
  - Peuvent être organisés en pools selon des contraintes (GPU, stockage, réseau spécifique...).
- Configurations DNS associées :
  - Ils doivent pouvoir résoudre l’API du cluster (`api.cluster.example.com`) et les autres services internes.
  - Les nœuds workers doivent aussi pouvoir résoudre le service de registre interne (`default-route-openshift-image-registry.apps.cluster.example.com`).
  - Exemple d’entrées DNS :
    ```
    worker-1.cluster.example.com → 192.168.1.21
    worker-2.cluster.example.com → 192.168.1.22
    ```

---

#### **1.3. Nœuds d’infrastructure (Infrastructure Nodes)**
- Rôles :
  - Hébergent les services essentiels au cluster (registre d’images, router, monitoring, logging…).
- Configurations DNS associées :
  - Doivent être accessibles par les autres nœuds pour exposer les services internes.
  - Ils ont souvent des noms spécifiques pour les distinguer des workers classiques :
    ```
    infra-1.cluster.example.com → 192.168.1.31
    infra-2.cluster.example.com → 192.168.1.32
    ```

---

### **2. Configuration DNS requise dans OpenShift**
#### **2.1. DNS Externe (Obligatoire pour l’installation)**
- **Entrées A et CNAME** pour les points d’accès API :
  ```
  api.cluster.example.com → IP du load balancer (ou master)
  api-int.cluster.example.com → IP du load balancer interne
  ```

#### **2.2. DNS Interne (géré par CoreDNS ou dnsmasq)**
- OpenShift utilise un **service DNS interne** basé sur CoreDNS pour la résolution des services internes.
- Exemple de noms de service internes :
  ```
  etcd-0.cluster.example.com → 192.168.1.12
  etcd-1.cluster.example.com → 192.168.1.13
  etcd-2.cluster.example.com → 192.168.1.14
  ```

- Les pods et services utilisent une résolution DNS basée sur `.cluster.local`, par exemple :
  ```
  my-app.my-namespace.svc.cluster.local
  ```
### 🔹 **Notion de "Tenant" dans OpenShift**  

Dans OpenShift, un **tenant** représente un **groupe isolé d’utilisateurs et de workloads** qui partagent des ressources tout en restant cloisonnés des autres groupes. OpenShift n’a pas un concept de "tenant" au sens strict, mais il permet de mettre en place une **multi-tenancy** grâce à plusieurs mécanismes.

---

### 🔹 **Les Mécanismes de Multi-Tenancy dans OpenShift**  

| **Mécanisme**       | **Rôle** |
|---------------------|---------|
| **Namespaces (Projects)** | Isolation des ressources et des workloads pour chaque tenant. |
| **RBAC (Role-Based Access Control)** | Gestion des droits et permissions des utilisateurs par projet. |
| **Network Policies** | Isolation réseau entre tenants/pods. |
| **Resource Quotas & LimitRanges** | Limitation des ressources (CPU, mémoire, etc.) par tenant. |
| **Security Contexts & SCC (Security Context Constraints)** | Contrôle de la sécurité des conteneurs et des permissions. |

---

### 🔹 **1️⃣ Isolation des Tenants avec des Namespaces**  

Un namespace (`project` dans OpenShift) est un espace de travail dédié aux workloads d’un tenant. Chaque tenant peut avoir son propre namespace où il exécute ses applications.

📌 **Exemple : Créer un namespace pour un tenant nommé "team1"**
```bash
oc new-project team1 --description="Tenant Team1" --display-name="Team 1"
```
➡ Ce namespace isole les ressources et évite toute interférence avec d’autres tenants.

---

### 🔹 **2️⃣ Gestion des Droits avec RBAC**  

OpenShift utilise **RBAC (Role-Based Access Control)** pour définir quels utilisateurs ou groupes peuvent accéder à quels namespaces.

📌 **Exemple : Donner accès à "team1" à un utilisateur spécifique**
```bash
oc adm policy add-role-to-user admin user1 -n team1
```
➡ L’utilisateur `user1` a un rôle d’**admin** sur le namespace `team1`, mais pas sur les autres namespaces.

---

### 🔹 **3️⃣ Isolation Réseau avec NetworkPolicies**  

Par défaut, dans OpenShift SDN, tous les pods peuvent communiquer entre eux. Pour isoler les tenants, on utilise **les NetworkPolicies**.

📌 **Exemple : Empêcher tout trafic entrant dans les pods du tenant "team1" sauf depuis son namespace**  
```yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: deny-external
  namespace: team1
spec:
  podSelector: {}
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: team1
```
➡ Cette règle **bloque tout trafic provenant d’autres namespaces**, sauf `team1` lui-même.

---

### 🔹 **4️⃣ Gestion des Ressources avec Resource Quotas**  

On peut limiter les ressources disponibles pour chaque tenant pour éviter qu’un utilisateur monopolise le cluster.

📌 **Exemple : Limiter un namespace à 4 CPU et 8 Go de RAM**
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: quota-team1
  namespace: team1
spec:
  hard:
    requests.cpu: "4"
    requests.memory: "8Gi"
    limits.cpu: "8"
    limits.memory: "16Gi"
```
➡ **Garantit que le tenant "team1" ne dépasse pas ces ressources.**

---

### 🔹 **5️⃣ Sécurité des Conteneurs avec SCC**  

OpenShift utilise **Security Context Constraints (SCC)** pour limiter les actions possibles des conteneurs dans un namespace.

📌 **Exemple : Empêcher un tenant d’exécuter des conteneurs en root**
```bash
oc adm policy add-scc-to-group restricted system:serviceaccounts:team1
```
➡ **Applique une politique de sécurité stricte sur les conteneurs du tenant "team1".**

---

### 🔹 **📌 Conclusion : Comment bien gérer la multi-tenancy ?**  

✔ **Créer un namespace par tenant**  
✔ **Configurer des rôles avec RBAC** pour éviter que les tenants ne voient d’autres ressources  
✔ **Appliquer des NetworkPolicies** pour isoler les communications  
✔ **Limiter les ressources avec Resource Quotas**  
✔ **Restreindre les permissions des conteneurs avec SCC**  

Tu veux mettre en place une séparation des tenants dans un environnement spécifique ? 😊
---

### 🔹 **Architecture d’un opérateur OpenShift/Kubernetes avec CRD**  

Un **opérateur** dans OpenShift/Kubernetes est une application qui automatise la gestion d’un logiciel complexe sur un cluster. Il repose sur le **pattern de contrôle** et utilise des **Custom Resource Definitions (CRD)** pour gérer des objets spécifiques à une application.

---

## **🔹 1️⃣ Composants clés d’un opérateur avec CRD**  

| **Composant**  | **Rôle** |
|---------------|---------|
| **Custom Resource Definition (CRD)** | Définit un nouvel objet personnalisé dans l’API Kubernetes. |
| **Custom Resource (CR)** | Instance du CRD qui décrit la configuration d’un service. |
| **Operator Controller** | Boucle de contrôle qui surveille les CR et applique les changements nécessaires. |
| **Reconciler** | Logique métier qui s’assure que l’état actuel correspond à l’état désiré. |
| **RBAC (Role-Based Access Control)** | Permissions d’accès pour l’opérateur dans le cluster. |

---

## **🔹 2️⃣ Architecture globale**  

L’opérateur suit le pattern **Controller-Operator** et fonctionne selon les étapes suivantes :  

1️⃣ **Définition d’un CRD** → Ajoute un nouvel objet (`MyApp`) dans l’API Kubernetes.  
2️⃣ **Création d’un CR** → Un utilisateur crée une ressource personnalisée (`MyApp-instance`).  
3️⃣ **Surveillance par le contrôleur** → L’opérateur détecte les changements sur le CR.  
4️⃣ **Reconciliation Loop** → L’opérateur applique les changements en créant/modifiant des ressources sous-jacentes (Pods, Services, ConfigMaps, etc.).  
5️⃣ **Mise à jour et gestion continue** → L’opérateur surveille en permanence et corrige tout écart.

---

## **🔹 3️⃣ Exemple d’architecture technique**

```yaml
# 📌 1️⃣ Définition du CRD (Custom Resource Definition)
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: myapps.example.com
spec:
  group: example.com
  names:
    kind: MyApp
    plural: myapps
  scope: Namespaced
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          replicas:
            type: integer
```

---

```yaml
# 📌 2️⃣ Création d’un CR (Custom Resource)
apiVersion: example.com/v1
kind: MyApp
metadata:
  name: myapp-instance
spec:
  replicas: 3
```

---

```go
// 📌 3️⃣ Contrôleur Go pour gérer le CR
func (r *MyAppReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {
    log := r.Log.WithValues("myapp", req.NamespacedName)

    // Récupérer l'état actuel du CR
    var myApp examplev1.MyApp
    if err := r.Get(ctx, req.NamespacedName, &myApp); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }

    // Vérifier et mettre à jour les ressources (ex: Deployment)
    desiredReplicas := myApp.Spec.Replicas
    err := r.updateDeployment(ctx, myApp, desiredReplicas)
    if err != nil {
        log.Error(err, "Erreur lors de la mise à jour")
        return ctrl.Result{}, err
    }

    return ctrl.Result{}, nil
}
```

---

## **🔹 4️⃣ Déploiement et gestion de l’opérateur**  

### ✅ **1. Construire l’opérateur avec Operator SDK**  
```bash
operator-sdk init --domain=example.com --repo=github.com/example/my-operator
operator-sdk create api --group=example --version=v1 --kind=MyApp --resource --controller
```

### ✅ **2. Déployer l’opérateur**  
```bash
make deploy
kubectl apply -f config/samples/example_v1_myapp.yaml
```

---

## **📌 Conclusion**
✔ **Les CRD** permettent d’ajouter des API personnalisées dans OpenShift/Kubernetes.  
✔ **L’opérateur** surveille et applique l’état désiré en boucle.  
✔ **Le reconciler** exécute la logique métier pour créer/modifier les ressources Kubernetes.  

Tu veux un opérateur pour un besoin spécifique, comme OpenShift ou une solution cloud ? 😊

### 🔹 **Types d’utilisateurs dans Kubernetes**  

Dans Kubernetes, les utilisateurs ne sont **pas** des objets gérés directement par l’API (contrairement aux ressources comme les Pods ou les Services). Ils sont définis de manière externe (via des certificats, des identités IAM, etc.).  

Il existe **deux types principaux d’utilisateurs** :  

| **Type**            | **Description** |
|---------------------|----------------|
| **Regular users (utilisateurs classiques)** | Représentent des humains accédant au cluster (ex: DevOps, Admins). |
| **System users (utilisateurs système)** | Représentent des services ou des composants internes de Kubernetes. |

---

## **🔹 1️⃣ Regular Users (Utilisateurs classiques)**  

Les **utilisateurs réguliers** sont des **humains** qui interagissent avec le cluster via `kubectl`, `oc` (OpenShift), l’API Kubernetes, ou des interfaces graphiques (comme OpenShift Console ou Lens).  

📌 **Caractéristiques :**  
✔ Ne sont **pas stockés** dans Kubernetes (gérés par des systèmes externes).  
✔ Authentification via **certificats X.509, OIDC, LDAP, IAM (Cloud)**, etc.  
✔ Accès contrôlé par **RBAC (Role-Based Access Control)**.  

📌 **Exemples de Regular Users :**  
- **Admin du cluster** (`admin`)  
- **Développeur** (`developer`)  
- **Opérateur DevOps** (`devops`)  

📌 **Exemple d’authentification par certificat X.509**  
```bash
kubectl config set-credentials taoufik --client-certificate=taoufik.crt --client-key=taoufik.key
```
➡ Ici, `taoufik` est un utilisateur classique identifié par un certificat.

---

## **🔹 2️⃣ System Users (Utilisateurs système)**  

Les **utilisateurs système** sont des comptes utilisés par Kubernetes pour ses propres composants et services.  

📌 **Caractéristiques :**  
✔ Ont un **préfixe `system:`** dans leur nom.  
✔ Gérés automatiquement par Kubernetes.  
✔ Utilisés pour la communication interne entre les composants Kubernetes.  
✔ Assignés à des **ServiceAccounts** pour l’authentification des Pods.  

📌 **Exemples de System Users :**  
| **Utilisateur**                | **Rôle** |
|---------------------------------|---------|
| `system:admin`                  | Administrateur du cluster (OpenShift). |
| `system:kube-controller-manager` | Gère les objets comme les Deployments, les Jobs… |
| `system:kube-scheduler`         | Planifie l’exécution des Pods sur les nœuds. |
| `system:kubelet`                | Exécute les Pods sur un nœud spécifique. |
| `system:serviceaccount:<namespace>:<name>` | Compte attribué aux Pods. |

📌 **Exemple de ServiceAccount attribué à un Pod :**  
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-app-sa
  namespace: my-namespace
```
➡ Ce ServiceAccount `my-app-sa` peut être utilisé par un Pod pour interagir avec l’API Kubernetes.

---

## **🔹 3️⃣ Différences entre Regular Users et System Users**  

| **Critère**        | **Regular Users** | **System Users** |
|--------------------|-----------------|----------------|
| **Type d’utilisateur** | Humains | Services/Kubernetes |
| **Stocké dans Kubernetes ?** | ❌ Non (externe) | ✅ Oui (géré en interne) |
| **Authentification** | Certificat X.509, OIDC, IAM | ServiceAccount, RBAC |
| **Utilisation principale** | Interaction avec le cluster (`kubectl`, API…) | Automatisation des composants Kubernetes |
| **Exemple d’utilisateur** | `taoufik`, `devops` | `system:kube-scheduler`, `system:serviceaccount:default:my-app` |

---

## **🔹 📌 Conclusion**  
✔ **Regular Users** 👉 Pour les humains interagissant avec Kubernetes (admins, devs, ops).  
✔ **System Users** 👉 Pour les composants internes de Kubernetes et les Pods.  
✔ L’accès est géré via **RBAC** et l’authentification dépend du contexte (certificats, OIDC, ServiceAccounts).  

Tu veux configurer un accès utilisateur spécifique sur un cluster OpenShift/K8s ? 😊

Voici un **diagramme de séquence** simplifié pour illustrer le processus de connexion à l'API OpenShift avec deux types de comptes différents : un **compte local** et un **compte externe via Keycloak**.

---

### **🔹 Diagramme de séquence : Connexion à l'API OpenShift**

---

#### **1️⃣ Connexion avec un compte local :**

1. **Utilisateur** envoie une demande de connexion à l'API OpenShift.
2. **API OpenShift** redirige la demande vers l'authentification locale (par exemple via `htpasswd`, certificat, ou autres mécanismes).
3. **Service d’authentification OpenShift** vérifie les **identifiants locaux**.
4. Si **authentification réussie**, **OpenShift** génère un **token d’accès** (Bearer Token).
5. L’**API OpenShift** répond avec le **token d’accès**.
6. **Utilisateur** peut maintenant faire des requêtes API avec le **token d’accès** dans l’en-tête.

---

#### **2️⃣ Connexion avec un compte externe via Keycloak :**

1. **Utilisateur** envoie une demande de connexion à l'API OpenShift.
2. **API OpenShift** redirige la demande vers **Keycloak** (serveur d'identité externe).
3. **Keycloak** demande à l’utilisateur de s’authentifier via **OIDC** (par exemple : via un formulaire de login).
4. **Utilisateur** saisit ses identifiants dans **Keycloak**.
5. **Keycloak** vérifie les identifiants de l’utilisateur contre sa base de données ou un fournisseur d'identité (LDAP, etc.).
6. Si **authentification réussie**, **Keycloak** génère un **token ID** (ID Token) et un **token d’accès** (Access Token).
7. **Keycloak** redirige l’utilisateur vers l'**API OpenShift** avec ces tokens.
8. **API OpenShift** valide les tokens via le **provider OIDC** (Keycloak).
9. Si la validation réussie, **OpenShift** génère un **token d’accès** valide pour l’utilisateur et le renvoie.
10. **Utilisateur** utilise le **token d’accès** pour faire des requêtes à l’API OpenShift.

---

### **🔹 Diagramme de séquence visuel :**

Voici une illustration pour mieux comprendre :

```plaintext
                    +-------------------+           +-------------------+           +-----------------+
                    |   Utilisateur     |           |   API OpenShift   |           |    Keycloak     |
                    +-------------------+           +-------------------+           +-----------------+
                             |                            |                               |
                             |     1. Demande de connexion                               |
                             | ------------------------> |                               |
                             |                            | 2. Authentification locale / OIDC|
                             |                            | <-------------------------+     |
                             |                            |                               |
                             |                            |                               |   
                             |                            | 3. Rediriger vers Keycloak (OIDC) |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            |                               |
                             |                            |                               |
                             |                            |    4. Demande d’identifiants     |
                             |                            | <----------------------------     |
                             |                            |                               |
                             |                            | 5. Vérification des identifiants |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            | 6. Token d'accès + ID Token     |
                             |                            | <----------------------------     |
                             |                            |                               |
                             |                            | 7. Rediriger vers OpenShift     |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            | 8. Validation des tokens       |
                             |                            | ---------------------------->     |
                             |                            |                               |
                             |                            | 9. Retourner le token d’accès  |
                             |                            | <----------------------------     |
                             |                            |                               |
                             |                            | 10. Requête API avec token d’accès|
                             | ------------------------> |                               |
```

---

### **🔹 Conclusion**

- **Compte local** : Authentification interne avec OpenShift, pas besoin de service externe.
- **Compte Keycloak** : Utilisation de l’OIDC pour l'authentification, avec un fournisseur externe (Keycloak), permettant une gestion centralisée des identités.

Cela te semble-t-il clair ou tu veux explorer un cas d’utilisation particulier ? 😊
